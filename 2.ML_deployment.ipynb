{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3387ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oracle-ads in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (2.8.6)\n",
      "Requirement already satisfied: oci>=2.102.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (2.104.2)\n",
      "Requirement already satisfied: fsspec>=0.8.7 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.19.2 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.23.3)\n",
      "Requirement already satisfied: pandas<1.6,>1.2.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.4.4)\n",
      "Requirement already satisfied: cerberus>=1.3.4 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.3.4)\n",
      "Requirement already satisfied: python-jsonschema-objects>=0.3.13 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (0.4.1)\n",
      "Requirement already satisfied: ocifs>=1.1.3 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.1.3)\n",
      "Requirement already satisfied: requests in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (2.28.1)\n",
      "Requirement already satisfied: scikit-learn<1.2,>=0.23.2 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.1.2)\n",
      "Requirement already satisfied: asteval>=0.9.25 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (0.9.27)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (4.64.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (0.8.10)\n",
      "Requirement already satisfied: cloudpickle>=1.6.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (2.0.0)\n",
      "Requirement already satisfied: PyYAML<6,>=5.4 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (5.4.1)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (3.5.2)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (5.9.0)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (3.0.3)\n",
      "Requirement already satisfied: gitpython>=3.1.2 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oracle-ads) (3.1.18)\n",
      "Requirement already satisfied: setuptools in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from cerberus>=1.3.4->oracle-ads) (65.5.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from gitpython>=3.1.2->oracle-ads) (4.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from jinja2>=2.11.2->oracle-ads) (2.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (1.4.4)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=17.5.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci>=2.102.0->oracle-ads) (22.0.0)\n",
      "Requirement already satisfied: cryptography<40.0.0,>=3.2.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci>=2.102.0->oracle-ads) (37.0.2)\n",
      "Requirement already satisfied: circuitbreaker<2.0.0,>=1.3.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci>=2.102.0->oracle-ads) (1.4.0)\n",
      "Requirement already satisfied: pytz>=2016.10 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci>=2.102.0->oracle-ads) (2022.6)\n",
      "Requirement already satisfied: certifi in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci>=2.102.0->oracle-ads) (2022.9.24)\n",
      "Requirement already satisfied: inflection>=0.2 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from python-jsonschema-objects>=0.3.13->oracle-ads) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from python-jsonschema-objects>=0.3.13->oracle-ads) (1.16.0)\n",
      "Requirement already satisfied: Markdown>=2.4 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from python-jsonschema-objects>=0.3.13->oracle-ads) (3.4.1)\n",
      "Requirement already satisfied: jsonschema>=2.3 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from python-jsonschema-objects>=0.3.13->oracle-ads) (4.7.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.23.2->oracle-ads) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.23.2->oracle-ads) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.23.2->oracle-ads) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from requests->oracle-ads) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from requests->oracle-ads) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from requests->oracle-ads) (2.1.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from cryptography<40.0.0,>=3.2.1->oci>=2.102.0->oracle-ads) (1.14.6)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.2->oracle-ads) (3.0.5)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from jsonschema>=2.3->python-jsonschema-objects>=0.3.13->oracle-ads) (5.10.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from jsonschema>=2.3->python-jsonschema-objects>=0.3.13->oracle-ads) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from jsonschema>=2.3->python-jsonschema-objects>=0.3.13->oracle-ads) (0.19.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from Markdown>=2.4->python-jsonschema-objects>=0.3.13->oracle-ads) (5.0.0)\n",
      "Requirement already satisfied: pycparser in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from cffi>=1.12->cryptography<40.0.0,>=3.2.1->oci>=2.102.0->oracle-ads) (2.21)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from importlib-metadata>=4.4->Markdown>=2.4->python-jsonschema-objects>=0.3.13->oracle-ads) (3.10.0)\n",
      "Requirement already satisfied: oci in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (2.104.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.5.3 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci) (2.8.2)\n",
      "Requirement already satisfied: cryptography<40.0.0,>=3.2.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci) (37.0.2)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=17.5.0 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci) (22.0.0)\n",
      "Requirement already satisfied: circuitbreaker<2.0.0,>=1.3.1 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci) (1.4.0)\n",
      "Requirement already satisfied: certifi in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci) (2022.9.24)\n",
      "Requirement already satisfied: pytz>=2016.10 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from oci) (2022.6)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from cryptography<40.0.0,>=3.2.1->oci) (1.14.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.5.3->oci) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages (from cffi>=1.12->cryptography<40.0.0,>=3.2.1->oci) (2.21)\n"
     ]
    }
   ],
   "source": [
    "# Upgrade Oracle ADS to pick up latest features and maintain compatibility with Oracle Cloud Infrastructure.\n",
    "\n",
    "!pip install -U oracle-ads\n",
    "!pip install --upgrade oci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6604dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/datascience/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/tmp/ipykernel_6134/3696504410.py:21: DeprecationWarning: The `ads.common.model_metadata` is deprecated in `oracle-ads 2.6.8` and will be removed in future release. Use the `ads.model.model_metadata` instead.\n",
      "  from ads.common.model_metadata import UseCaseType\n",
      "\n",
      "WARNING:py.warnings:/tmp/ipykernel_6134/3696504410.py:23: DeprecationWarning: The `ads.common.model_export_util` is deprecated in `oracle-ads 2.6.9` and will be removed in `oracle-ads 3.0`. Use framework specific Model utility class for saving and deploying model. Check https://accelerated-data-science.readthedocs.io/en/latest/user_guide/model_registration/quick_start.html\n",
      "  from ads.common.model_export_util import prepare_generic_model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요 라이브러리 Import\n",
    "\n",
    "import ads\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import warnings\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "import joblib\n",
    "\n",
    "import ocifs\n",
    "import oci\n",
    "from ocifs import OCIFileSystem\n",
    "\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "from ads.common.model_export_util import prepare_generic_model\n",
    "from ads.model.framework.sklearn_model import SklearnModel\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817edc8a",
   "metadata": {},
   "source": [
    "<font color=gray>Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2023 Oracle, Inc.  All rights reserved.\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.\n",
    "</font>\n",
    "\n",
    "***\n",
    "# <font color=red>Sklearn으로 만들 모델 배포하기</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=teal> Oracle Cloud Infrastructure Data Science Service Team </font></p>\n",
    "\n",
    "***\n",
    "\n",
    "## Overview:\n",
    "\n",
    "Accelerated Data Science(ADS)의 'SklearnModel' 클래스는 모델을 신속하게 생성하고 배포할 수 있도록 설계되었습니다. \n",
    "- `.prepare()` 메서드는 모델을 구성하거나 코드를 작성할 필요 없이 작동하는 모델을 배포하는 데 필요한 모델 아티팩트를 생성합니다. \n",
    "- `score.py` 파일은 필요에 따라 사용자 정의할 수 있습니다. \n",
    "- `.verify()` 메서드를 사용하여 배포된 모델에 대한 호출을 시뮬레이션합니다. 이 메서드는 `score.py` 파일에서 `load_model()` 및 `predict()` 함수를 호출합니다. `.verify()`를 사용하면 모델을 배포하지 않고도 `score.py` 파일을 디버그할 수 있습니다. \n",
    "- `.save()` 메서드는 `SklearnModel` 및 모델 아티팩트를 모델 카탈로그로 푸시합니다. \n",
    "- `.deploy()` 메서드는 모델을 REST 끝점에 배포합니다. \n",
    "- `.predict()` 메서드를 사용하면 엔드포인트를 호출하여 모델 추론을 수행할 수 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59895d58",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction\n",
    "\n",
    "## Authenticate\n",
    "\n",
    "OCI Data Science 서비스에 대한 인증이 필요합니다. 여기서는 기본적으로 resource principal을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7075c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.set_auth(auth=\"resource_principal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c7397",
   "metadata": {},
   "source": [
    "<a id=\"intro_dataset\"></a>\n",
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39446b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket에 있는 크롤링 데이터 import\n",
    "# 한국어 및 테스트 데이터 삭제 \n",
    "# nan과 null 데이터 처리를 위해 desc열만 dataframe으로 변환 \n",
    "\n",
    "crawled_parquet_df = pd.read_json(\"oci://crawled_data@apackrsct01/enhanced_livelabs.json\")\n",
    "df_final=crawled_parquet_df.drop([402,409,462,774,788])\n",
    "df_final1 = pd.DataFrame({'document':df_final.desc})\n",
    "df_final2 = df_final1.dropna()\n",
    "df_final3 = df_final2[df_final2['document'].astype(bool)]\n",
    "crawled_final = list(df_final3.document.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed9a942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, learning_offset=50.0,\n",
       "                          n_components=15, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, learning_offset=50.0,\n",
       "                          n_components=15, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          n_components=15, random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer로 벡터화기 구현\n",
    "# 최종 데이터 crwaled_final을 transform 후 LDA 알고리즘으로 Topic Modeling 생성\n",
    "\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))\n",
    "    \n",
    "tf_vectorizer = LemmaCountVectorizer(max_df=0.95, \n",
    "                                     min_df=2,\n",
    "                                     stop_words='english',\n",
    "                                     decode_error='ignore')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(crawled_final)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=15, max_iter=10,\n",
    "                                learning_method = 'online',\n",
    "                                learning_offset = 50.,\n",
    "                                random_state = 0)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82f2859f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic #0</th>\n",
       "      <th>Topic #1</th>\n",
       "      <th>Topic #2</th>\n",
       "      <th>Topic #3</th>\n",
       "      <th>Topic #4</th>\n",
       "      <th>Topic #5</th>\n",
       "      <th>Topic #6</th>\n",
       "      <th>Topic #7</th>\n",
       "      <th>Topic #8</th>\n",
       "      <th>Topic #9</th>\n",
       "      <th>Topic #10</th>\n",
       "      <th>Topic #11</th>\n",
       "      <th>Topic #12</th>\n",
       "      <th>Topic #13</th>\n",
       "      <th>Topic #14</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.440892</td>\n",
       "      <td>0.461027</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.083535</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.195667</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.774447</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.349957</td>\n",
       "      <td>0.168790</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.453667</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.945098</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.452900</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.525962</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.547624</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.425292</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.664176</td>\n",
       "      <td>0.237519</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.056199</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.816381</td>\n",
       "      <td>0.168930</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.262334</td>\n",
       "      <td>0.554998</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.163156</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.961111</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.863894</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.087958</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic #0  Topic #1  Topic #2  Topic #3  Topic #4  Topic #5  Topic #6  \\\n",
       "0   0.001212  0.001212  0.440892  0.461027  0.001212  0.001212  0.001212   \n",
       "1   0.002299  0.002299  0.002299  0.195667  0.002299  0.002299  0.774447   \n",
       "2   0.002299  0.002299  0.349957  0.168790  0.002299  0.002299  0.002299   \n",
       "3   0.001058  0.001058  0.985185  0.001058  0.001058  0.001058  0.001058   \n",
       "4   0.003922  0.003922  0.003922  0.945098  0.003922  0.003922  0.003922   \n",
       "5   0.001626  0.452900  0.001626  0.525962  0.001626  0.001626  0.001626   \n",
       "6   0.001587  0.001587  0.977778  0.001587  0.001587  0.001587  0.001587   \n",
       "7   0.002083  0.002083  0.002083  0.547624  0.002083  0.002083  0.002083   \n",
       "8   0.003509  0.003509  0.664176  0.237519  0.003509  0.003509  0.056199   \n",
       "9   0.002381  0.002381  0.002381  0.966667  0.002381  0.002381  0.002381   \n",
       "10  0.001130  0.001130  0.816381  0.168930  0.001130  0.001130  0.001130   \n",
       "11  0.001626  0.001626  0.262334  0.554998  0.001626  0.001626  0.001626   \n",
       "12  0.002778  0.002778  0.002778  0.961111  0.002778  0.002778  0.002778   \n",
       "13  0.002083  0.002083  0.002083  0.970833  0.002083  0.002083  0.002083   \n",
       "14  0.006667  0.006667  0.906667  0.006667  0.006667  0.006667  0.006667   \n",
       "15  0.003175  0.003175  0.955556  0.003175  0.003175  0.003175  0.003175   \n",
       "16  0.003704  0.003704  0.863894  0.003704  0.003704  0.003704  0.003704   \n",
       "17  0.002083  0.002083  0.970833  0.002083  0.002083  0.002083  0.002083   \n",
       "18  0.005556  0.005556  0.922222  0.005556  0.005556  0.005556  0.005556   \n",
       "19  0.009524  0.009524  0.866667  0.009524  0.009524  0.009524  0.009524   \n",
       "\n",
       "    Topic #7  Topic #8  Topic #9  Topic #10  Topic #11  Topic #12  Topic #13  \\\n",
       "0   0.001212  0.083535  0.001212   0.001212   0.001212   0.001212   0.001212   \n",
       "1   0.002299  0.002299  0.002299   0.002299   0.002299   0.002299   0.002299   \n",
       "2   0.002299  0.453667  0.002299   0.002299   0.002299   0.002299   0.002299   \n",
       "3   0.001058  0.001058  0.001058   0.001058   0.001058   0.001058   0.001058   \n",
       "4   0.003922  0.003922  0.003922   0.003922   0.003922   0.003922   0.003922   \n",
       "5   0.001626  0.001626  0.001626   0.001626   0.001626   0.001626   0.001626   \n",
       "6   0.001587  0.001587  0.001587   0.001587   0.001587   0.001587   0.001587   \n",
       "7   0.002083  0.425292  0.002083   0.002083   0.002083   0.002083   0.002083   \n",
       "8   0.003509  0.003509  0.003509   0.003509   0.003509   0.003509   0.003509   \n",
       "9   0.002381  0.002381  0.002381   0.002381   0.002381   0.002381   0.002381   \n",
       "10  0.001130  0.001130  0.001130   0.001130   0.001130   0.001130   0.001130   \n",
       "11  0.001626  0.163156  0.001626   0.001626   0.001626   0.001626   0.001626   \n",
       "12  0.002778  0.002778  0.002778   0.002778   0.002778   0.002778   0.002778   \n",
       "13  0.002083  0.002083  0.002083   0.002083   0.002083   0.002083   0.002083   \n",
       "14  0.006667  0.006667  0.006667   0.006667   0.006667   0.006667   0.006667   \n",
       "15  0.003175  0.003175  0.003175   0.003175   0.003175   0.003175   0.003175   \n",
       "16  0.087958  0.003704  0.003704   0.003704   0.003704   0.003704   0.003704   \n",
       "17  0.002083  0.002083  0.002083   0.002083   0.002083   0.002083   0.002083   \n",
       "18  0.005556  0.005556  0.005556   0.005556   0.005556   0.005556   0.005556   \n",
       "19  0.009524  0.009524  0.009524   0.009524   0.009524   0.009524   0.009524   \n",
       "\n",
       "    Topic #14  dominant_topic  \n",
       "0    0.001212               3  \n",
       "1    0.002299               6  \n",
       "2    0.002299               8  \n",
       "3    0.001058               2  \n",
       "4    0.003922               3  \n",
       "5    0.001626               3  \n",
       "6    0.001587               2  \n",
       "7    0.002083               3  \n",
       "8    0.003509               2  \n",
       "9    0.002381               3  \n",
       "10   0.001130               2  \n",
       "11   0.001626               3  \n",
       "12   0.002778               3  \n",
       "13   0.002083               3  \n",
       "14   0.006667               2  \n",
       "15   0.003175               2  \n",
       "16   0.003704               2  \n",
       "17   0.002083               2  \n",
       "18   0.005556               2  \n",
       "19   0.009524               2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Topic modeling data 결과\n",
    "\n",
    "doc_topics=lda.transform(tf)\n",
    "\n",
    "topic_index=list(df_final3.index.values)\n",
    "topic_names = ['Topic #'+str(i) for i in range(0,15)]\n",
    "topic_df = pd.DataFrame(data=doc_topics, columns=topic_names,index=topic_index)\n",
    "\n",
    "dominant_topic = np.argmax(topic_df.values, axis=1)\n",
    "topic_df['dominant_topic'] = dominant_topic\n",
    "topic_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5439f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=topic_df.drop(['dominant_topic'],axis=1)\n",
    "y=topic_df['dominant_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d77f7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainx, trainy, testx, testy = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280be586",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9cdc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(init=&#x27;random&#x27;, n_clusters=15, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(init=&#x27;random&#x27;, n_clusters=15, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(init='random', n_clusters=15, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans(\n",
    "     init=\"random\",\n",
    "     n_clusters=15,\n",
    "     n_init=10,\n",
    "     max_iter=300,\n",
    "     random_state=42\n",
    " )\n",
    "\n",
    "model.fit(trainx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b5fc5c",
   "metadata": {},
   "source": [
    "## 모델 준비\n",
    "\n",
    "데이터를 위한 임시 디렉토리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8855b656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.common:In the future model input will be serialized by `cloudpickle` by default. Currently, model input are serialized into a dictionary containing serialized input data and original data type information.Set `model_input_serializer=\"cloudpickle\"` to use cloudpickle model input serializer.\n",
      "WARNING:py.warnings:/home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages/ads/model/runtime/env_info.py:92: UserWarning: slug will be deprecated. Provide conda pack path instead.s]\n",
      "  warnings.warn(\"slug will be deprecated. Provide conda pack path instead.\")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "algorithm: KMeans\n",
       "artifact_dir:\n",
       "  /tmp/tmpik1bgavn:\n",
       "  - - score.py\n",
       "    - model.joblib\n",
       "    - input_schema.json\n",
       "    - output_schema.json\n",
       "    - .model-ignore\n",
       "    - runtime.yaml\n",
       "framework: scikit-learn\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir = tempfile.mkdtemp()\n",
    "sklearn_model = SklearnModel(estimator=model, artifact_dir=artifact_dir)\n",
    "sklearn_model.prepare(\n",
    "    inference_conda_env=\"generalml_p38_cpu_v1\",\n",
    "    training_conda_env=\"generalml_p38_cpu_v1\",\n",
    "    use_case_type=UseCaseType.CLUSTERING,\n",
    "    X_sample=trainx,\n",
    "    y_sample=trainy,\n",
    "    force_overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dddb6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Available     Local tested .predict from score.py                               \n",
       "save()    Available     Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03d2dd",
   "metadata": {},
   "source": [
    "## Verify\n",
    "\n",
    "verify 메서드는 artifact_dir의 ``score.py`` 내부에 정의된 ``predict`` 함수를 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85268bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /tmp/tmpik1bgavn ...\n",
      "Model is successfully loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': [9, 4, 8, 9, 4, 9, 4, 3, 13, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.verify(trainx[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e37412",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72203321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /tmp/tmpik1bgavn ...\n",
      "Model is successfully loaded.\n",
      "['score.py', 'model.joblib', 'input_schema.json', 'output_schema.json', '.model-ignore', 'runtime.yaml']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ocid1.datasciencemodel.oc1.ap-seoul-1.amaaaaaavsea7yiaoasqiohz6cprgfb4aclz6wd7jfs4pidaoqjckpygsz5a'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.save(display_name=\"model-minjikim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84dacd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Done          Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1031435",
   "metadata": {},
   "source": [
    "## Deploy\n",
    "\n",
    "모델이 모델 카탈로그에 있으면 모델의 `.deploy()` 메서드를 사용하여 배포할 수 있습니다. \n",
    "이 방법을 사용하면 표시 이름, 설명, 인스턴스 유형 및 개수, 최대 대역폭, 로깅 그룹과 같은 배포 속성을 지정할 수 있습니다. \n",
    "다음 셀은 사용자 지정 표시 이름을 제외한 기본 설정으로 모델을 배포합니다. \n",
    "`.deploy()` 메서드는 `ModelDeployment` 개체를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86c2a244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deploy = sklearn_model.deploy(\n",
    "    display_name=\"deployment-minjikim\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9ee2cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Actions Needed\n",
       "Step      Status    Details                                                           \n",
       "initiate  Done      Initiated the model                                               \n",
       "prepare() Done      Generated runtime.yaml                                            \n",
       "                    Generated score.py                                                \n",
       "                    Serialized model                                                  \n",
       "                    Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done      Local tested .predict from score.py                               \n",
       "save()    Done      Conducted Introspect Test                                         \n",
       "                    Uploaded artifact to model catalog                                \n",
       "deploy()  ACTIVE    Deployed the model                                                \n",
       "predict() Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be119986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://modeldeployment.ap-seoul-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.ap-seoul-1.amaaaaaavsea7yiavx2mgda6weinn2m7bf3zb6cbe5y24i2qqutlvbok6q6a\n"
     ]
    }
   ],
   "source": [
    "print(f\"Endpoint: {sklearn_model.model_deployment.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059dd6db",
   "metadata": {},
   "source": [
    "# Invoke & Predict \n",
    "\n",
    "이번 단계에서는 모델 엔드포인트를 호출하여 Sample Data에 대한 예측 결과를 확인해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fa46c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer\n",
    "\n",
    "auth = oci.auth.signers.get_resource_principals_signer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc9cfb",
   "metadata": {},
   "source": [
    "아래 셀을 실행하기 전에 모델 배포의 URI를 복사하여 붙여넣으세요. Model Deployment의 세부 정보 페이지의 **Resources** 메뉴에서 **\"Invoking your model\"**을 클릭합니다. 모델의 HTTP 끝점을 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c1cad76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://modeldeployment.ap-seoul-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.ap-seoul-1.amaaaaaavsea7yiaeagi3me4tdy4x4xy5thiw5hj6srm5empuzw7lfwbcyaa/predict\n"
     ]
    }
   ],
   "source": [
    "#uri = f\"<replace-with-your-model-deployment-uri\"\n",
    "uri = f\"<replace-with-your-model-deployment-uri\"\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78262d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\"I want to learn about machine learning model using heatwave\"]\n",
    "sample_vec = tf_vectorizer.transform(sample)\n",
    "topic_probability_scores = lda.transform(sample_vec)\n",
    "input_data = pd.DataFrame(topic_probability_scores).to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7296508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.6 ms, sys: 51 µs, total: 16.7 ms\n",
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = requests.post(uri, json=input_data, auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670abc82",
   "metadata": {},
   "source": [
    "상태 코드를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "249f818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert response.status_code == 200, 'Error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fcb005",
   "metadata": {},
   "source": [
    "그리고 호출한 모델을 사용한 예측 결과입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05118c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [14]}\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response.content)['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc20d2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/generalml_p38_cpu_v1/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KMeans was fitted with feature names\n",
      "  warnings.warn(\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  771\n",
      "title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Time Series Forecasting with fb Prophet\n",
      "url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=771\n",
      "type                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Hands-on\n",
      "desc              The Oracle Cloud Infrastructure Data Science service is a fully managed, self-service platform for data science teams to build, train, and manage machine learning (ML) models in Oracle Cloud Infrastructure.  This lab will go through the steps of setting up a project and a JupyterLab notebook session in OCI Data Science.  We will go through the process of building a time series model, a type of machine learning problem encountered in a variety of industries including finance, retail and transportation.   We will explore a time series dataset and construct data visualizations.  We will build and train time series models with different machine learning packages including Statsmodels and Prophet, and we will analyze and  compare the model performance.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        2 hours\n",
      "published_time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2018-09-05 02:23:40\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        fb Prophet을 사용하여 시계열 예측\n",
      "desc_ko                                                                                                                                                                                                                                                                                                                                                                                       Oracle Cloud Infrastructure Data Science 서비스는 데이터 과학 팀이 Oracle Cloud Infrastructure에서 머신 러닝(ML) 모델을 구축, 교육 및 관리할 수 있는 전담 관리 셀프서비스 플랫폼입니다. 이 실습에서는 OCI Data Science에서 프로젝트 및 JupyterLab 노트북 세션을 설정하는 단계를 진행합니다. 재무, 소매 및 운송을 비롯한 다양한 산업에서 발생하는 머신 러닝 문제인 시계열 모델을 구축하는 과정을 거치게 됩니다. 시계열 데이터 세트를 탐색하고 데이터 시각화를 구성합니다. Statsmodels 및 Prophet을 포함한 다양한 머신 러닝 패키지를 사용하여 시계열 모델을 구축하고 교육하며 모델 성능을 분석하고 비교할 것입니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2시간\n",
      "oci_products                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          notebook,cloud infrastructure data science service,prophet,statsmodels,machine learning,machine learning packages\n",
      "key_phrase                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  time series forecasting,self-service platform,data science teams,machine learning,oracle cloud infrastructure,jupyterlab notebook session,oci data science,time series model,machine learning problem,variety of industries\n",
      "Name: 145, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                3306\n",
      "title                                                                                                                                                                                                                                                                                                                 Get started with MySQL HeatWave Machine Learning\n",
      "url                                                                                                                                                                                                                                                                                    https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=3306\n",
      "type                                                                                                                                                                                                                                                                                                                                                          Hands-on\n",
      "desc              In this workshop, users will learn to implement the \"Iris Flowers\" project with  HeatWave Machine Learning (ML). This project is also known as the Hello World version of Machine Learning. The user will create a HeatWave MySQL database system and build a predictive machine learning model using the Machine Learning capabilities of HeatWave.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                       2 hours\n",
      "published_time                                                                                                                                                                                                                                                                                                                                     2021-03-17 12:28:07\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                     MySQL HeatWave 머신 러닝 시작하기\n",
      "desc_ko                                                                                                                                                                 이 워크샵에서는 HeatWave ML(머신 러닝)을 사용하여 \"Iris Flowers\" 프로젝트를 구현하는 방법을 배웁니다. 이 프로젝트는 Hello World 버전의 머신 러닝이라고도 합니다. 사용자는 HeatWave MySQL 데이터베이스 시스템을 생성하고 HeatWave의 머신 러닝 기능을 사용하여 예측 머신 러닝 모델을 구축합니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                        2시간\n",
      "oci_products                                                                                                                                                                                                                                                                            hello world,heatwave,heatwave mysql,heatwave machine learning,machine learning\n",
      "key_phrase                                                                                                                                       mysql heatwave machine learningin,iris flowers,heatwave machine learning,hello world version,machine learning,heatwave mysql database system,predictive machine learning model,machine learning capabilities,users,ml\n",
      "Name: 548, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                782\n",
      "title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Predicting Auto Claim Fraud with Oracle Machine Learning\n",
      "url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=782\n",
      "type                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Hands-on\n",
      "desc              Automotive insurance fraud involves someone deceiving an insurance company about a claim involving their personal or commercial motor vehicle. It can involve giving out misleading information or providing false documentation to support the claim. This workshop highlights the use of two Oracle Machine Learning notebooks working in conjunction with automobile insurance claims investigators in a two-step process. First, we use Oracle Machine Learning to “flag” for the investigator anomalous insurance claims using an unsupervised learning algorithm (1-Class Support Vector Machine). We help the claims investigators focus on the most suspicious claims using their expertise and knowledge using an Oracle APEX application.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1 hour\n",
      "published_time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    2018-09-26 19:43:14\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Oracle Machine Learning으로 자동 청구 사기 예측\n",
      "desc_ko                                                                                                                                                                                                                                                                                                                                                    자동차 보험 사기에는 개인 또는 상업용 자동차와 관련된 청구에 대해 보험 회사를 속이는 사람이 포함됩니다. 여기에는 잘못된 정보를 제공하거나 청구를 지원하기 위해 잘못된 문서를 제공하는 작업이 포함될 수 있습니다. 이 워크숍에서는 2단계 프로세스에서 자동차 보험 청구 조사관과 함께 작동하는 2개의 Oracle Machine Learning 노트북 사용을 집중적으로 다룹니다. 첫째, Oracle Machine Learning을 사용하여 비지도 학습 알고리즘(1등급 Support Vector Machine)을 사용하여 조사관 비정상적인 보험 청구에 대해 \"플래그\"합니다. 청구 조사자는 Oracle APEX 애플리케이션을 사용하여 전문 지식과 지식을 사용하여 가장 의심스러운 청구에 집중할 수 있습니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1시간\n",
      "oci_products                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             automobile insurance,commercial motor vehicle,auto,insurance\n",
      "key_phrase                                                                                                                                                                                                                                                                                                                                                                                                                                                                         predicting auto claim fraud,insurance company,misleading information,false documentation,automobile insurance claims investigators,two-step process,oracle machine learning,investigator anomalous insurance claims,unsupervised learning algorithm,1-class support vector machine\n",
      "Name: 154, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     3444\n",
      "title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         League of Legends Machine Learning with OCI - Introduction to Neural Networks\n",
      "url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=3444\n",
      "type                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Hands-on\n",
      "desc              Neural Networks are becoming increasingly popular in the AI/ML space, and people who don’t know anything about Neural Networks often get scared about the terminology used by industry practitioners. In reality, it’s much easier to get started with a NN than what you would think. In this Hands-On Lab, we’re going to introduce concepts from NNs, applied to a specific problem in the Gaming industry (related to one of the most popular videogames, League of Legends, with over 3 million daily players), and see what tools we have available to get started with Neural Networks in OCI in an practical way.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1 hour, 30 minutes\n",
      "published_time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2021-10-25 07:45:10\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               League of Legends Machine Learning with OCI - 신경망 소개\n",
      "desc_ko                                                                                                                                                                                                                                                                                                                                                    신경망은 AI/ML 공간에서 점점 대중화되고 있으며 신경망에 대해 모르는 사람들은 종종 업계 실무자가 사용하는 용어를 두려워합니다. 실제로 NN을 시작하는 것이 생각보다 훨씬 쉽습니다. 이 실습 랩에서는 NN의 개념을 소개하고, 게임 산업의 특정 문제(가장 인기 있는 비디오 게임 중 하나인 League of Legends와 3백만 명 이상의 일일 플레이어)에 적용하며, OCI에서 Neural Networks를 시작하는 데 사용할 수 있는 도구를 실제적인 방법으로 확인할 수 있습니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1시간 30분\n",
      "oci_products                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          neural networks,neural,neural networksneural networks\n",
      "key_phrase                                                                                                                                                                                                                                                                                                                                                                                                                                   neural networks,legends machine learning,oci - introduction,neural networksneural networks,ai/ml space,industry practitioners,hands-on lab,specific problem,gaming industry,popular videogames\n",
      "Name: 641, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                  560\n",
      "title                                                                                                                                                                                                                                                                           Machine Learning on Autonomous Database\n",
      "url                                                                                                                                                                                                                                      https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=560\n",
      "type                                                                                                                                                                                                                                                                                                           Hands-on\n",
      "desc              Oracle integrates machine learning across the Oracle stack and the enterprise, fully leveraging Oracle Database and Oracle Autonomous Database.  In this workshop, create a machine learning model and move the model to ADB.  Explore machine learning notebooks and use prediction in applications.\n",
      "duration                                                                                                                                                                                                                                                                                                        2 hours\n",
      "published_time                                                                                                                                                                                                                                                                                      2017-09-04 05:55:07\n",
      "title_ko                                                                                                                                                                                                                                                                                     Autonomous Database의 머신 러닝\n",
      "desc_ko                                                                                                                                    Oracle은 Oracle Database와 Oracle Autonomous Database를 완전히 활용하여 Oracle 스택과 기업 전반에 머신 러닝을 통합합니다. 이 워크샵에서는 머신 러닝 모델을 생성하고 모델을 ADB로 이동합니다. 머신 러닝 노트북을 살펴보고 애플리케이션에서 예측 기능을 사용합니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                         2시간\n",
      "oci_products                                                                                                                                                                                                                                                                adb,machine learning notebooks,applications\n",
      "key_phrase                                                                                         machine learning,autonomous databaseoracle integrates machine,oracle stack,leveraging oracle database,oracle autonomous database,machine learning model,explore machine learning notebooks,enterprise,adb,prediction\n",
      "Name: 2, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3209\n",
      "title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Oracle Machine Learning Services: Model Deployment using REST\n",
      "url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=3209\n",
      "type                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Hands-on\n",
      "desc              With the introduction of Oracle Machine Learning Services with Oracle Autonomous Database, Oracle makes it easy for data science teams and application developers to manage and deploy machine learning models using a REST API, and for ease of application integration. OML Services extends OML functionality to support model deployment and model lifecycle management for both in-database OML models and third-party Open Neural Networks Exchange (ONNX) format machine learning models through REST APIs.In this workshop, we are going to crate, train, deploy and score machine learning models based on customer insurance data using Autonomous Database and tools like AutoML User Interface, and OML Services and REST APIs.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              4 hours\n",
      "published_time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            2020-08-14 17:04:11\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Oracle Machine Learning Services: REST를 사용한 모델 배포\n",
      "desc_ko                                                                                                                                                                                                                                                                                                Oracle Autonomous Database의 Oracle Machine Learning Services가 도입됨에 따라 Oracle은 데이터 과학 팀과 애플리케이션 개발자가 REST API를 사용하여 머신 러닝 모델을 쉽게 관리하고 배포할 수 있으며 간편한 애플리케이션 통합이 가능합니다. OML 서비스는 OML 기능을 확장하여 REST를 통해 데이터베이스 내 OML 모델 및 타사 OONNX(Open Neural Networks Exchange) 형식 머신 러닝 모델에 대한 모델 배포 및 모델 라이프사이클 관리를 지원합니다. APIs.In이 워크숍에서는 Autonomous Database와 AutoML 사용자 인터페이스, OML 서비스 및 REST API와 같은 툴을 사용하여 고객 보험 데이터를 기반으로 머신 러닝 모델을 생성, 교육, 배포 및 점수를 매길 수 있습니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               4시간\n",
      "oci_products                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   machine learning services,automl,apis,rest api\n",
      "key_phrase                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         oracle machine learning services,oml services,model deployment,using restwith,oracle autonomous database,machine learning models,rest api,ease of application integration,oml functionality,format machine learning models\n",
      "Name: 465, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                         922\n",
      "title                                                                                                                                                                                                                      Get started with Oracle Machine Learning Fundamentals on Oracle Autonomous Database\n",
      "url                                                                                                                                                                                                                             https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=922\n",
      "type                                                                                                                                                                                                                                                                                                  Hands-on\n",
      "desc              Get a quick tour of Oracle Machine Learning technologies on Autonomous Database. Use OML Notebooks to create and evaluate models and score data using SQL, Python and R. Use OML Services REST API to deploy models and score data. Use AutoML UI for a no-code machine learning experience.\n",
      "duration                                                                                                                                                                                                                                                                                   2 hours, 30 minutes\n",
      "published_time                                                                                                                                                                                                                                                                             2019-06-08 06:59:05\n",
      "title_ko                                                                                                                                                                                                                                Oracle Autonomous Database에서 Oracle Machine Learning Fundamentals 시작하기\n",
      "desc_ko                                                                      Autonomous Database에서 Oracle Machine Learning 기술을 빠르게 살펴볼 수 있습니다. OML 노트북을 사용하여 SQL, Python 및 R을 사용하여 모델을 생성하고 평가하며 데이터에 점수를 부여합니다. OML Services REST API를 사용하여 모델을 배포하고 데이터에 점수를 부여합니다. 코딩이 필요 없는 머신 러닝 환경을 위해 AutoML UI를 사용합니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                            2시간 30분\n",
      "oci_products                                                                                                                                                                                                                                    sql,python,notebooks,r,automl ui,machine learning technologies\n",
      "key_phrase                                                                             models,oracle machine learning fundamentals,oracle autonomous databaseget,quick tour,oracle machine learning technologies,autonomous database,oml notebooks,using sql,use automl ui,no-code machine learning experience\n",
      "Name: 268, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                    3286\n",
      "title                                                                                                                                                                                                                                                                                                                                  Full-Text Search in Oracle Database\n",
      "url                                                                                                                                                                                                                                                                                        https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=3286\n",
      "type                                                                                                                                                                                                                                                                                                                                                              Hands-on\n",
      "desc              Oracle Text provides full-text indexing capabilities for Oracle database, allowing you to search textual content (such as VARCHAR2 or CLOB data) by specifying words, phrases, or other textual patterns within the content.The workshop is aimed at developers and DBAs, and covers creating indexes, basic search capabilities, and index maintenance.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                            1 hour\n",
      "published_time                                                                                                                                                                                                                                                                                                                                         2021-02-08 01:41:28\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                       Oracle Database에서 전체 텍스트 검색\n",
      "desc_ko                                                                                                                                                             Oracle Text는 Oracle 데이터베이스에 대한 전체 텍스트 인덱스화 기능을 제공하므로 content.The 워크샵 내에서 단어, 구문 또는 기타 텍스트 패턴을 지정하여 텍스트 콘텐츠(예: VARCHAR2 또는 CLOB 데이터)를 검색할 수 있습니다. 개발자와 DBA를 대상으로 하며 인덱스 생성, 기본 검색 기능 및 인덱스 유지 관리를 다룹니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                            1시간\n",
      "oci_products                                                                                                                                                                                                                                                                                                                                            clob data,varchar2\n",
      "key_phrase                                                                                                                                                          full-text search,oracle databaseoracle text,full-text indexing capabilities,oracle database,textual content,clob data,specifying words,other textual patterns,content.the workshop,developers and dbas\n",
      "Name: 533, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    3470\n",
      "title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Accelerate Your Journey to OCI Using Oracle Enterprise Landing Zone\n",
      "url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=3470\n",
      "type                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Hands-on\n",
      "desc              One of the biggest challenges for customers looking to make the move to a public cloud is the time and resource investment needed to understand how to do so in the best way to allow them to be successful. This effort can take many months if not years through numerous hours of research and POCs which is a challenge both in time and money with no guarantee of success. OCI Landing Zones solves this customer headache by allowing customers to perform one-click, best-practice deployments of multiple Oracle services at once, enabling their rapid onboarding into OCI. Based on Terraform, Landing Zones deploy the OCI core services needed prior to deploying workloads into the cloud.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1 hour, 30 minutes\n",
      "published_time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2021-12-11 04:31:57\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Oracle Enterprise 랜딩존을 사용하여 OCI로의 여정 가속화\n",
      "desc_ko                                                                                                                                                                                                                                                                                                                                                                 퍼블릭 클라우드로 전환하려는 고객이 직면한 가장 큰 과제 중 하나는 성공할 수 있는 최상의 방법으로 마이그레이션 방법을 이해하는 데 필요한 시간과 리소스 투자입니다. 이러한 노력은 성공 보장없이 시간과 돈 모두에서 도전 인 수많은 연구 및 POC를 통해 년이 아닌 경우 몇 개월이 걸릴 수 있습니다. OCI 랜딩존은 고객이 한 번에 여러 Oracle 서비스의 원클릭 모범 사례 배포를 수행하여 OCI로의 신속한 온보딩을 가능하게 함으로써 이 고객의 부담을 해결합니다. Terraform을 기반으로 하는 Landing Zones는 워크로드를 클라우드에 배포하기 전에 필요한 OCI 핵심 서비스를 배포합니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1시간 30분\n",
      "oci_products                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN\n",
      "key_phrase                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             biggest challenges,public cloud,time and resource investment,best way,many months,not years,numerous hours,research and pocs,time and money,no guarantee of success\n",
      "Name: 661, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                    3079\n",
      "title                                                                                                                                                                                                                            Detect anomalies with OML4SQL with one-class support vector machine (SVM)\n",
      "url                                                                                                                                                                                                                        https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=3079\n",
      "type                                                                                                                                                                                                                                                                                              Hands-on\n",
      "desc              OML4SQL enables SQL developers to use machine learning algorithms in the Oracle Database.  It is for those looking to process data in place without moving the data out of the database. This allows you to leverage the high performance database to process data for machine learning.\n",
      "duration                                                                                                                                                                                                                                                                                           2 hours\n",
      "published_time                                                                                                                                                                                                                                                                         2020-03-13 08:07:42\n",
      "title_ko                                                                                                                                                                                                                                         SVM(One-class support vector machine)을 통해 OML4SQL으로 변형 감지\n",
      "desc_ko                                                                                                                                 OML4SQL를 사용하면 SQL 개발자가 Oracle Database에서 머신 러닝 알고리즘을 사용할 수 있습니다. 데이터베이스에서 데이터를 이동하지 않고 제자리에 데이터를 처리하려는 사용자를 위한 것입니다. 이를 통해 고성능 데이터베이스를 활용하여 머신 러닝 데이터를 처리할 수 있습니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                            2시간\n",
      "oci_products                                                                                                                                                                                                                                                                    support vector machine,svm\n",
      "key_phrase                                                                                                                               oml4sql,one-class support vector machine,sql developers,machine learning algorithms,oracle database,high performance database,machine learning,anomalies,database\n",
      "Name: 408, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     701\n",
      "title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     DB Security - Privilege Analysis\n",
      "url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=701\n",
      "type                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Hands-on\n",
      "desc              In this lab you will learn to use Privilege Analysis, a new feature introduced in Oracle Database 12c, to identify unused and potentially excess privileges assigned to database user accounts. Most database breaches involve the use of compromised user accounts - that means that every time you remove an unnecessary privilege from an account you shrink the attack surface area and minimize the blast radius in the event of a successful compromise. Privilege Analysis gives you an alternative to traditional privilege attestation where you just print a list of users and their roles/privileges for review. With Privilege Analysis, you can enrich those reports with  information on privileges that are assigned, but not being used over a period of time. Privilege Analysis is an included feature of Oracle Database Enterprise Edition.This lab is included in the DB Security Basics lab. If you have completed that lab, then there is no need to do this one.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        15 minutes\n",
      "published_time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2018-04-14 05:03:46\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     DB 보안 - 권한 분석\n",
      "desc_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         이 연습에서는 Oracle Database 12c에 도입된 새로운 기능인 Privilege Analysis를 사용하여 데이터베이스 유저 계정에 할당된 사용되지 않고 잠재적으로 초과된 권한을 식별하는 방법을 배웁니다. 대부분의 데이터베이스 침해에는 손상된 사용자 계정 사용이 포함됩니다. 즉, 계정에서 불필요한 권한을 제거할 때마다 공격 영역은 축소되고 성공적인 손상이 발생할 경우 폭발 반경은 최소화됩니다. 권한 분석은 검토를 위해 사용자 목록과 해당 역할/권한만 인쇄하는 기존 권한 증명 대신 사용할 수 있습니다. 권한 분석을 사용하면 할당되었지만 일정 기간 동안 사용되지 않는 권한에 대한 정보로 해당 보고서를 보강할 수 있습니다. 권한 분석은 Oracle Database Enterprise Edition의 포함된 기능입니다. 이 실습은 DB 보안 기본 사항 실습에 포함되어 있습니다. 이 실습을 완료한 경우에는 이를 수행할 필요가 없습니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           15분후\n",
      "oci_products                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN\n",
      "key_phrase                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        privilege analysis,lab,db security,privilege analysisin,new feature,oracle database 12c,excess privileges,database user,most database breaches,compromised user accounts\n",
      "Name: 90, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                         3575\n",
      "title                                                                                                                                                                                                                                                                                                                                         Get Started With Oracle Analytics\n",
      "url                                                                                                                                                                                                                                                                                             https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=3575\n",
      "type                                                                                                                                                                                                                                                                                                                                                                   Hands-on\n",
      "desc              This workshop is the hands-on component of the live course \"Getting Started With Oracle Analytics.\" Users will walk through the basic components of Oracle Analytics, such as getting familiar with the UI, and basic features, such as creating a basic visualization canvas, utilizing Augmented Analytics, and leveraging Advanced Analytics capabilities.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                             49 minutes\n",
      "published_time                                                                                                                                                                                                                                                                                                                                              2022-07-11 10:13:22\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                                  Oracle Analytics 시작하기\n",
      "desc_ko                                                                                                                                                                                                                    이 워크샵은 라이브 과정 \"Oracle Analytics 시작하기\"의 실습 구성 요소입니다. 사용자는 UI에 익숙해지는 등 Oracle Analytics의 기본 구성요소와 기본 시각화 캔버스 생성, 증강 분석 활용, 고급 분석 기능 활용 등의 기본 기능을 익힙니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                                49분후\n",
      "oci_products                                                                                                                                                                                                                                                                                                                                                                NaN\n",
      "key_phrase                                                                                                                                              oracle analytics,oracle analyticsthis workshop,hands-on component,live course,basic components,basic features,basic visualization canvas,utilizing augmented analytics,leveraging advanced analytics capabilities,users\n",
      "Name: 755, dtype: object\n",
      "\n",
      "id                                                                                                                                                                                                                                                                                                                                                                                   836\n",
      "title                                                                                                                                                                                                                                                                                                                                                                JSON without Limits\n",
      "url                                                                                                                                                                                                                                                                                                       https://apexapps.oracle.com/pls/apex/r/dbpm/livelabs/run-workshop?p210_wid=836\n",
      "type                                                                                                                                                                                                                                                                                                                                                                            Hands-on\n",
      "desc              Oracle database brings simplicity and productivity to developers by removing every barrier to manage JSON data. Discover an ideal week of a developer bringing new features and fixing bugs quite easily: streaming data, indexing, reporting… This workshop presents advanced technics to combine numerous capabilities to solve everyday data management challenges.\n",
      "duration                                                                                                                                                                                                                                                                                                                                                                      30 minutes\n",
      "published_time                                                                                                                                                                                                                                                                                                                                                       2018-12-27 19:31:14\n",
      "title_ko                                                                                                                                                                                                                                                                                                                                                                      제한 없는 JSON\n",
      "desc_ko                                                                                                                                                                                       Oracle 데이터베이스는 JSON 데이터를 관리하는 모든 장벽을 제거하여 개발자에게 단순성과 생산성을 제공합니다. 데이터 스트리밍, 인덱싱, 보고 등 새로운 기능을 제공하고 버그를 쉽게 수정하는 개발자 일주일 동안 이상적이세요. 이 워크숍은 일상적인 데이터 관리 문제를 해결하기 위해 다양한 기능을 결합하는 고급 기술을 제공합니다.\n",
      "duration_ko                                                                                                                                                                                                                                                                                                                                                                          30분\n",
      "oci_products                                                                                                                                                                                                                                                                                                                                                                limitsoracle\n",
      "key_phrase                                                                                                                                                                                    limitsoracle database,simplicity and productivity,json data,ideal week,new features,fixing bugs,streaming data,advanced technics,numerous capabilities,everyday data management challenges\n",
      "Name: 199, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_cluster = model.predict(topic_probability_scores)\n",
    "data_points_in_cluster = trainx[model.labels_ == predicted_cluster]\n",
    "indices = data_points_in_cluster.index\n",
    "\n",
    "for index in indices:\n",
    "    print(crawled_parquet_df.loc[index])\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d0896c",
   "metadata": {},
   "source": [
    "<a id='clean_up'></a>\n",
    "# Clean Up\n",
    "\n",
    "이 노트북은 모델 배포와 모델을 만들었습니다. 이 섹션에서는 해당 리소스를 정리합니다.\n",
    "\n",
    "모델을 삭제하려면 먼저 모델 배포를 삭제해야 합니다. 이를 수행하려면 `SklearnModel` 개체에서 `.delete_deployment()` 메서드를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb9a6aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "delete = sklearn_model.delete_deployment(wait_for_completion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df6144",
   "metadata": {},
   "source": [
    "모델 배포가 삭제된 후 `.summary_status()` 메서드는 모델이 삭제되었고 `predict()` 메서드를 사용할 수 없음을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9632a69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>DELETED</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Done          Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  DELETED       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650007fc",
   "metadata": {},
   "source": [
    "`.delete()` 메서드를 사용하여 모델을 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca3eceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81da1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f246364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://modeldeployment.ap-seoul-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.ap-seoul-1.amaaaaaavsea7yiaeagi3me4tdy4x4xy5thiw5hj6srm5empuzw7lfwbcyaa/predict\n"
     ]
    }
   ],
   "source": [
    "uri = f\"https://modeldeployment.ap-seoul-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.ap-seoul-1.amaaaaaavsea7yiaeagi3me4tdy4x4xy5thiw5hj6srm5empuzw7lfwbcyaa/predict\"\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34c0c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Resource principal to authenticate against the model endpoint. Set using_rps=False if you are using \n",
    "# the config+key flow. \n",
    "using_rps = True\n",
    "\n",
    "# payload: \n",
    "input_data = trainx[5:25].to_json()\n",
    "\n",
    "if using_rps: # using resource principal:     \n",
    "    auth = oci.auth.signers.get_resource_principals_signer()\n",
    "else: # using config + key: \n",
    "    config = oci.config.from_file(\"~/.oci/config\") # replace with the location of your oci config file\n",
    "    auth = Signer(\n",
    "        tenancy=config['tenancy'],\n",
    "        user=config['user'],\n",
    "        fingerprint=config['fingerprint'],\n",
    "        private_key_file_location=config['key_file'],\n",
    "        pass_phrase=config['pass_phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d5cb9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 ms, sys: 2.66 ms, total: 17.5 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "# submit request to model endpoint: \n",
    "response = requests.post(uri, json=input_data, auth=auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45487c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert response.status_code == 200, 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76efa87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [0, 8, 3, 8, 7, 0, 2, 7, 4, 0, 10, 0, 6, 0, 0, 6, 6, 6, 8, 8]}\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a585a71a",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "# References\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)\n",
    "- [Understanding Conda Environments](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/use-notebook-sessions.htm#conda_understand_environments)\n",
    "- [Use Resource Manager to Configure Your Tenancy for Data Science](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/orm-configure-tenancy.htm)\n",
    "- [`runtime.yaml`](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/model_runtime_yaml.htm#model_runtime_yaml)\n",
    "- [`score.py`](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/model_score_py.htm#model_score_py)\n",
    "- [Model artifact](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/models_saving_catalog.htm#create-models)\n",
    "- [ONNX API Summary](http://onnx.ai/sklearn-onnx/api_summary.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p38_cpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p38_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
